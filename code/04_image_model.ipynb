{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification baseline\n",
    "\n",
    "This is a first test with the [Pl@ntNet-300k](https://github.com/plantnet/PlantNet-300K/tree/main) dataset. Pretrained models are available at [their website](https://lab.plantnet.org/seafile/d/01ab6658dad6447c95ae/).  \n",
    "There are several different pretrained models available, but we will start with the [resnet152](https://lab.plantnet.org/seafile/d/01ab6658dad6447c95ae/files/?p=%2Fresnet152_weights_best_acc.tar) version.  \n",
    "\n",
    "\n",
    "## 0 - Prerequisites\n",
    " 1. Download the pretrained [model](https://lab.plantnet.org/seafile/d/01ab6658dad6447c95ae/files/?p=%2Fresnet152_weights_best_acc.tar) and put it in the `/data/pretrained_image_models` folder.\n",
    "  \n",
    "https://lab.plantnet.org/seafile/d/01ab6658dad6447c95ae/files/?p=%2Fvit_base_patch16_224_weights_best_acc.tar\n",
    "## 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from timm import create_model\n",
    "\n",
    "from lightning import LightningModule, Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "seed_everything(42)\n",
    "\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "import imageio.v3 as imageio\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import wandb\n",
    "\n",
    "from os import path\n",
    "import gc\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data\"\n",
    "IMAGES_PATH = BASE_PATH + \"/train_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Custom Dataset\n",
    "We created a custom ImageDataset based on pytorchs Dataset. This dataset is used to load the images from the `data` folder and apply the necessary transformations. The dataset is then used to create a DataLoader which is used to feed the images to the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, dataset_path, transforms):\n",
    "        super().__init__()\n",
    "        self.transforms = transforms\n",
    "        self.dataset = pd.read_csv(dataset_path)\n",
    "        self.dataset[\"file_path\"] = root + \"/\" + self.dataset[\"id\"].astype(str) + \".jpeg\"\n",
    "        self.dataset[\"jpeg_bytes\"] = self.dataset[\"file_path\"].progress_apply(lambda fp: open(fp, \"rb\").read())\n",
    "\n",
    "        self.target_columns = [\"X4\", \"X11\", \"X18\", \"X26\", \"X50\", \"X3112\"]\n",
    "        if self.target_columns[0] not in self.dataset.columns:\n",
    "            self.target_columns = [f\"{col}_mean\" for col in self.target_columns]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.dataset.iloc[index]\n",
    "\n",
    "        image = self.transforms(image=imageio.imread(sample[\"jpeg_bytes\"]))[\"image\"]\n",
    "\n",
    "        targets = tensor(sample[self.target_columns].astype(float).values, dtype=torch.float32)\n",
    "        \n",
    "        return image, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Model\n",
    "Our ImageModel gets a model_type as a string, which is used to load the correct model from the `pretrained_image_models` folder. The model is then loaded and the last layer is replaced with a new layer which has the correct number of output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageModel(LightningModule):\n",
    "    def __init__(self, model_type, model_path, learning_rate = 1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.load_model(model_type, model_path)\n",
    "        self.set_last_layer(model_type)\n",
    "        \n",
    "        self.loss = MSELoss()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x, y = batch\n",
    "        \n",
    "        output = self.model(x)\n",
    "        \n",
    "        loss = self.loss(output, y)\n",
    "\n",
    "        metric = R2Score()\n",
    "        metric.update(output, y)\n",
    "        \n",
    "        return loss, metric.compute()\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss, r2 = self(batch)\n",
    "        self.log(\"Train loss\", loss, prog_bar=True)\n",
    "        self.log(\"Train R2\", r2)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def validation_step(self, batch):\n",
    "        loss, r2 = self(batch)\n",
    "        self.log(\"Validation loss\", loss, on_epoch=True)\n",
    "        self.log(\"Validation R2\", r2, on_epoch=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        match self.hparams.model_type:\n",
    "            case \"resnet152\" | \"resnet18\":\n",
    "                pretrained, classifier = self.get_split_params(\"fc\")\n",
    "            case \"vit_base_patch16_224\":\n",
    "                pretrained, classifier = self.get_split_params(\"head\")            \n",
    "            case _:\n",
    "                pretrained, classifier = self.get_split_params(\"classifier\")\n",
    "        \n",
    "        optimizer_params = [{\"params\": pretrained, \"lr\": self.hparams.learning_rate / 10}]\n",
    "        optimizer_params += [{\"params\": classifier, \"lr\": self.hparams.learning_rate}]\n",
    "        optimizer = Adam(params=optimizer_params)\n",
    "\n",
    "        scheduler = LinearLR(optimizer)\n",
    "        \n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def get_split_params(self, classifier_name):\n",
    "        pretrained = []\n",
    "        classifier = []\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name.startswith(classifier_name):\n",
    "                pretrained.append(param)\n",
    "            else:\n",
    "                classifier.append(param)\n",
    "        \n",
    "        return pretrained, classifier\n",
    "    \n",
    "    def load_model(self, model_type, model_path):\n",
    "        filename = f\"{model_path}/{model_type}.tar\"\n",
    "        if not path.exists(filename):\n",
    "            raise FileNotFoundError\n",
    "\n",
    "        self.get_model(model_type, filename)\n",
    "\n",
    "    def get_model(self, model_type, filename):\n",
    "        d = torch.load(filename)\n",
    "        \n",
    "        match model_type:\n",
    "            case \"resnet152\":\n",
    "                model = resnet152(num_classes=1081)\n",
    "            case \"resnet18\":\n",
    "                model = resnet18(num_classes=1081)\n",
    "            case \"densenet121\":\n",
    "                model = densenet121(num_classes=1081)\n",
    "            case \"densenet201\":\n",
    "                model = densenet201(num_classes=1081)\n",
    "            case _:\n",
    "                model = create_model(model_type, pretrained=True, num_classes=1081)\n",
    "\n",
    "        self.model = model\n",
    "        self.model.load_state_dict(d[\"model\"])\n",
    "\n",
    "    def get_sequential_layer(self):\n",
    "        sequence = Sequential()\n",
    "        for i in range(self.hparams.num_layers):\n",
    "            sequence.append(Linear(self.model.classifier.in_features, self.model.classifier.in_features))\n",
    "            sequence.append(ReLU())\n",
    "        sequence.append(Linear(self.model.classifier.in_features, 6))\n",
    "\n",
    "        return sequence\n",
    "\n",
    "    def set_last_layer(self, model_type):\n",
    "        match model_type:\n",
    "            case \"resnet152\" | \"resnet18\":\n",
    "                nr_ftrs = self.model.fc.in_features\n",
    "                #self.set_hidden_dim(nr_ftrs)\n",
    "                self.model.fc = Linear(nr_ftrs, 6)\n",
    "            case \"vit_base_patch16_224\":\n",
    "                nr_ftrs = self.model.head.in_features\n",
    "                #self.set_hidden_dim(nr_ftrs)\n",
    "                self.model.head = Linear(nr_ftrs, 6)                \n",
    "            case _:\n",
    "                nr_ftrs = self.model.classifier.in_features\n",
    "                #self.set_hidden_dim(nr_ftrs)\n",
    "                self.model.classifier = Linear(nr_ftrs, 6)\n",
    "\n",
    "    def set_hidden_dim(self, in_ftr):\n",
    "        self.hparams.hidden_dim = self.hparams.hidden_dim if self.hparams.hidden_dim > 2 else in_ftr * self.hparams.hidden_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Training\n",
    "### 4.1 - Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomSizedCrop(\n",
    "            [448, 512],\n",
    "            IMAGE_SIZE, IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n",
    "        A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n",
    "        A.ToFloat(),\n",
    "        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = ImageDataset(BASE_PATH + \"/train_images\", BASE_PATH + \"/cleaned/cleaned_train.csv\", transforms=transforms)\n",
    "train, val = random_split(image_dataset, [0.9, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Sweep function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep(config = None):\n",
    "    wandb.finish()    \n",
    "    with wandb.init() as run:\n",
    "        wandb.define_metric(\"Validation R2\", summary=\"max\")\n",
    "        \n",
    "        config = wandb.config\n",
    "        \n",
    "        model = ImageModel(config[\"model_type\"], BASE_PATH + \"/models\", config[\"learning_rate\"])\n",
    "\n",
    "        logger = WandbLogger(project=\"aicomp\", log_model=\"all\")\n",
    "\n",
    "        callbacks = [ModelCheckpoint(monitor=\"Validation R2\", mode=\"max\")]\n",
    "        callbacks += [EarlyStopping(monitor=\"Validation loss\", mode=\"min\", patience=30)]\n",
    "        callbacks += [EarlyStopping(monitor=\"Validation R2\", mode=\"max\", patience=30)]\n",
    "        callbacks += [EarlyStopping(monitor=\"Train loss\", mode=\"min\", patience=30, stopping_threshold=0.01, check_on_train_epoch_end=True)]\n",
    "        callbacks += [EarlyStopping(monitor=\"Train R2\", mode=\"max\", patience=30, stopping_threshold=0.99, check_on_train_epoch_end=True)]\n",
    "        callbacks += [LearningRateMonitor(logging_interval=\"step\")]\n",
    "        \n",
    "        trainer = Trainer(max_epochs=150, logger=logger, num_sanity_val_steps=0, callbacks=callbacks)\n",
    "\n",
    "        num_workers = 120\n",
    "        \n",
    "        train_dataloader = DataLoader(train, batch_size=120, shuffle=True, num_workers=num_workers)\n",
    "        val_dataloader = DataLoader(val, batch_size=120, num_workers=num_workers)\n",
    "        \n",
    "        trainer.fit(model, train_dataloader, val_dataloader)\n",
    "\n",
    "        run.finish()\n",
    "\n",
    "        del model\n",
    "        del trainer\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "wandb.agent(\"nlpfs24/aicomp/stjn09mr\", sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.teardown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
