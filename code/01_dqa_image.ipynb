{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images DQA  \n",
    "In this notebook we will evaluate the quality of the images in the dataset. For statistical analysis we will just have a look at the image count and compare it with data on the [kaggle page](https://www.kaggle.com/c/cassava-leaf-disease-classification/data):\n",
    "- Traing images: 55.5k\n",
    "- Validation images: 13.9k  \n",
    "\n",
    "\n",
    "Additionally we will have a look at the quality of the images themselves. For this, we will use the [cleanvision Imagelab library](https://github.com/cleanlab/cleanvision).  \n",
    "With this library we can easily check for the following issues:\n",
    "- Duplicates\n",
    "- Near duplicates\n",
    "- Blurry images\n",
    "- Low Information\n",
    "- Dark images\n",
    "- Light images\n",
    "- Grayscale images\n",
    "- Odd aspect ratio\n",
    "- Odd image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from cleanvision import Imagelab\n",
    "\n",
    "from matplotlib.pyplot import subplots\n",
    "from matplotlib.image import imread\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data/\"\n",
    "TRAIN_IMAGES = BASE_PATH + \"train_images/\"\n",
    "VAL_IMAGES = BASE_PATH + \"test_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_id_from_path(image_path):\n",
    "    return image_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "def pretty_print(ids):\n",
    "    return \"\\n\".join(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training and validation images, walk through the folder and check the image count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in [TRAIN_IMAGES, VAL_IMAGES]:\n",
    "    files = [f for f in listdir(folder) if isfile(join(folder, f))]\n",
    "    print(f\"Number of files in {folder}: {len(files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are exactly the numbers we found on kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Image quality: train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Load images and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelab = Imagelab(TRAIN_IMAGES)\n",
    "imagelab.find_issues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Image sizes\n",
    "First, lets have a look at the distribution of image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelab.info[\"statistics\"][\"size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each and every image has a size of 512x512 pixels, therefore no cleaning has to be done based on the image size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Report\n",
    "Imagelabe tells us that there are 84 issues in our training data. Therefore, we will check the imagelab report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelab.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Issue analysis\n",
    "#### 3.4.1 - Duplicates  \n",
    "The report states that there are 50 duplicates in the training data. We will have a look at the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image1, image2 in imagelab.info[\"exact_duplicates\"][\"sets\"]:\n",
    "\tfig, ax = subplots(1, 2)\n",
    "\tax[0].imshow(imread(image1))\n",
    "\tax[0].set_title(image1.split(\"/\")[-1])\n",
    "\tax[1].imshow(imread(image2))\n",
    "\tax[1].set_title(image2.split(\"/\")[-1])\n",
    "\tfig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the plots above, there are really only 25 duplicates. Considering that the training set has 55.5k entries, we'll just remove them from the tabular data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [parse_id_from_path(image2) for _, image2 in imagelab.info[\"exact_duplicates\"][\"sets\"]]\n",
    "\n",
    "print(f\"Number of duplicates to remove: {len(ids)}:\\n{pretty_print(sorted(ids, reverse=True))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 - Other issues\n",
    "The report states, that there are 34 other issues. Considering that the near duplicates are counted twice, this leaves us with 26 issues. In the scope of 55.5k training images, we're not going to analyze them, but rather just remove them alltogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids += [parse_id_from_path(image2) for _, image2 in imagelab.info[\"near_duplicates\"][\"sets\"]]\n",
    "\n",
    "ids += [parse_id_from_path(image) for image in imagelab.issues[imagelab.issues[\"is_blurry_issue\"] == True].index.tolist()]\n",
    "\n",
    "ids += [parse_id_from_path(image) for image in imagelab.issues[imagelab.issues[\"is_dark_issue\"] == True].index.tolist()]\n",
    "\n",
    "ids += [parse_id_from_path(image) for image in imagelab.issues[imagelab.issues[\"is_low_information_issue\"] == True].index.tolist()]\n",
    "\n",
    "ids += [parse_id_from_path(image) for image in imagelab.issues[imagelab.issues[\"is_light_issue\"] == True].index.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For duplicate id removal, we're casting the list to a set and afterwards saving them to a csv file to be imported in the tabular data dqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ids))\n",
    "pd.DataFrame({\"id\": sorted(list(set(ids)), reverse=True)}).to_csv(BASE_PATH + \"train_ids_to_remove.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Image quality: validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 - Load images and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelab = Imagelab(VAL_IMAGES)\n",
    "imagelab.find_issues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Image sizes\n",
    "Again, let's have a look at the distribution of image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelab.info[\"statistics\"][\"size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the training data, all the images are the same 512x512 pixels in the validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Issue analysis\n",
    "Compared to the training dataset, there are even less issues. We're not even going to analyze them further and just remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagelab.issue_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [parse_id_from_path(image2) for _, image2 in imagelab.info[\"exact_duplicates\"][\"sets\"]]\n",
    "\n",
    "ids += [parse_id_from_path(image2) for _, image2 in imagelab.info[\"near_duplicates\"][\"sets\"]]\n",
    "\n",
    "ids += [parse_id_from_path(image) for image in imagelab.issues[imagelab.issues[\"is_blurry_issue\"] == True].index.tolist()]\n",
    "\n",
    "ids += [parse_id_from_path(image) for image in imagelab.issues[imagelab.issues[\"is_dark_issue\"] == True].index.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before with the training dataset, were casting the list to a set to remove duplicates and afterwards save them to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ids))\n",
    "pd.DataFrame({\"id\": sorted(list(set(ids)), reverse=True)}).to_csv(BASE_PATH + \"val_ids_to_remove.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
